{
	"name": "Data_cleaning_with_enya_partB",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "9036f83c-9876-4695-9626-1e887f596649"
			}
		},
		"metadata": {
			"saveOutput": true,
			"synapse_widget": {
				"version": "0.1"
			},
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "python"
			},
			"language_info": {
				"name": "python"
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"source": [
					"## Reuse cleaning function that was previously registered"
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"source": [
					"import pandas as pd\n",
					"import datetime as dt\n",
					"import re\n",
					"import enya as en\n",
					"from enya import SemanticDataFrame\n",
					"from enya.model import Attribute, LogicalType\n",
					"from enya.kb.kb import KB\n",
					"import logging\n",
					"logging.getLogger('cdm-python').setLevel(logging.ERROR)"
				],
				"attachments": null,
				"execution_count": 1
			},
			{
				"cell_type": "code",
				"metadata": {
					"tags": []
				},
				"source": [
					"# Load CDM model with registered kb\n",
					"KB = en.KB()\n",
					"KB.make_default()\n",
					"\n",
					"KB.load_from_manifest(\"local:/cdm/jobsModel.manifest.cdm.json\", path_to_kb=\"data/kb_partA/enya_kb.pkl\") \n",
					"\n",
					"# Obtain the semantic dataframe corresponding to jobsEntity\n",
					"sdf = KB.get_data(\"jobsEntity\")\n",
					""
				],
				"attachments": null,
				"execution_count": 2
			},
			{
				"cell_type": "code",
				"source": [
					"sdf.standardize()"
				],
				"attachments": null,
				"execution_count": 3
			},
			{
				"cell_type": "code",
				"source": [
					"sdf[\"PreciseTimeStamp\"].sample(10)"
				],
				"attachments": null,
				"execution_count": 4
			},
			{
				"cell_type": "code",
				"source": [
					"#Check type of transformed_PTS column\n",
					"sdf.dtypes"
				],
				"attachments": null,
				"execution_count": 5
			},
			{
				"cell_type": "code",
				"source": [
					"#Generic method for running group by with selection query\n",
					"def run_query(df, query_condition, group_by_attr, agg_required):\n",
					"    d1 = df.query(query_condition)\n",
					"    return d1.groupby(df[group_by_attr].dt.hour).agg(agg_required)"
				],
				"attachments": null,
				"execution_count": 6
			},
			{
				"cell_type": "code",
				"metadata": {
					"tags": []
				},
				"source": [
					"# Counting scale-up\n",
					"query_result = run_query(sdf, 'Operation == \"AutoScaleUp\"', \"PreciseTimeStamp\", ['count'])\n",
					"query_result"
				],
				"attachments": null,
				"execution_count": 7
			},
			{
				"cell_type": "code",
				"metadata": {
					"tags": []
				},
				"source": [
					"# Counting scale-down\n",
					"query_result = run_query(sdf, 'Operation == \"AutoScaleDown\"', 'PreciseTimeStamp', ['count'])\n",
					"query_result"
				],
				"attachments": null,
				"execution_count": 8
			},
			{
				"cell_type": "code",
				"source": [
					""
				],
				"attachments": null,
				"execution_count": null
			}
		]
	}
}